{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6132b9f-59d7-4fb3-9413-e9412d458b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training data\n",
    "train_df = pd.read_csv('D:/MLPR/timeseries/train.csv', parse_dates=['date'])\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('D:/MLPR/timeseries/test.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f5b7708-67ec-43b8-a307-0a9e59291aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the 'family' column\n",
    "train_df = pd.get_dummies(train_df, columns=['family'])\n",
    "test_df = pd.get_dummies(test_df, columns=['family'])\n",
    "\n",
    "# Ensure both train and test data have the same columns after encoding\n",
    "train_df, test_df = train_df.align(test_df, join='left', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdc38d28-fb00-4821-bf94-6adf4aa54803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your features and target variable\n",
    "X = train_df.drop(['sales', 'id', 'date'], axis=1)\n",
    "y = train_df['sales']\n",
    "\n",
    "# Split the data chronologically\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ad1eb-6b81-4079-9530-a910823ba931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05d090de-a85c-42ba-b477-d77669a2d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special characters in column names with underscores\n",
    "X_train.columns = X_train.columns.str.replace(r'\\W', '_', regex=True)\n",
    "X_valid.columns = X_valid.columns.str.replace(r'\\W', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65373116-5668-40f5-8820-7bfb83c057c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# Check the number of features\n",
    "print(X_train.shape[1])  # Number of features in training set\n",
    "print(len(X_train.columns))  # Number of feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54252602-f5d8-4083-980b-ff011aa743bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure feature names are set\n",
    "X_train.columns = [f'feature_{i}' for i in range(X_train.shape[1])]\n",
    "X_valid.columns = [f'feature_{i}' for i in range(X_valid.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb979747-9f98-4229-ab52-223db3d243d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure non-negative predictions\n",
    "y_pred = np.maximum(y_pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da3a672b-33ff-48dc-b7a1-46eff754ca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 128\n",
      "[LightGBM] [Info] Number of data points in the train set: 838860, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 237.373651\n",
      "Root Mean Squared Logarithmic Error: 2.014349266756285\n",
      "Mean Squared Error: 156996.57431136616\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "\n",
    "# Initialize the model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# Ensure non-negative predictions\n",
    "y_pred = np.maximum(y_pred, 0)\n",
    "\n",
    "# Evaluate the model using Mean Squared Logarithmic Error\n",
    "rmsle = mean_squared_log_error(y_valid, y_pred, squared=False)\n",
    "print(f'Root Mean Squared Logarithmic Error: {rmsle}')\n",
    "\n",
    "# Alternatively, evaluate using Mean Squared Error\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ad26726-050f-4a3f-820c-99d4763ca648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'D:/MLPR/timeseries/submission.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('D:/MLPR/timeseries/test.csv', parse_dates=['date'])\n",
    "\n",
    "# One-hot encode the 'family' column\n",
    "test_df = pd.get_dummies(test_df, columns=['family'])\n",
    "\n",
    "# Load the training data and align columns\n",
    "train_df = pd.read_csv('D:/MLPR/timeseries/train.csv', parse_dates=['date'])\n",
    "train_df = pd.get_dummies(train_df, columns=['family'])\n",
    "X_train = train_df.drop(['sales', 'id', 'date'], axis=1)\n",
    "\n",
    "# Prepare test data with alignment\n",
    "# Ensure test data has the same columns as the training data\n",
    "test_df = test_df.drop(['id', 'date'], axis=1, errors='ignore')  # Drop columns if they exist\n",
    "\n",
    "# Align columns\n",
    "test_df = test_df.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Initialize the trained model (assuming itâ€™s already trained)\n",
    "# If the model is not trained, you need to train it here\n",
    "# model = LGBMRegressor()\n",
    "# model.fit(X_train, y_train)  # Only if you need to retrain, otherwise use the pre-trained model\n",
    "\n",
    "# Make predictions\n",
    "test_predictions = model.predict(test_df)\n",
    "\n",
    "# Ensure non-negative predictions\n",
    "test_predictions = np.maximum(test_predictions, 0)\n",
    "\n",
    "# Prepare and save the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df.get('id', pd.Series([None]*len(test_df))),  # Handle case if 'id' is missing\n",
    "    'sales': test_predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('D:/MLPR/timeseries/submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'D:/MLPR/timeseries/submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffa542-77e6-472d-9f96-fca3209df6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
